
import express from 'express';
import cors from 'cors';
import { GoogleGenAI, Modality } from '@google/genai';
import dotenv from 'dotenv';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

dotenv.config();

const app = express();
const port = process.env.PORT || 3000;

app.use(cors());
app.use(express.json({ limit: '100mb' }));

// Serve frontend static files (from the 'dist' folder generated by 'npm run build')
app.use(express.static(path.join(__dirname, 'dist')));

// API Endpoint: Analyze Video & Generate Script
app.post('/api/analyze-script', async (req, res) => {
  try {
    const { videoData, mimeType, targetLanguageCode } = req.body;
    const apiKey = process.env.API_KEY;
    
    if (!apiKey) return res.status(500).json({ error: "Server API_KEY is missing." });
    if (!videoData) return res.status(400).json({ error: "Missing video data." });

    const ai = new GoogleGenAI({ apiKey });
    const model = "gemini-3-flash-preview"; 
    
    const prompt = `
      Professional Video Dubbing Task:
      Identify speakers and translate all dialogue into ${targetLanguageCode}.
      Output exactly in this JSON format:
      {
        "speakers": [{ "id": "Speaker A", "gender": "MALE" }],
        "script": [{ "speakerId": "Speaker A", "text": "Translated dialog" }]
      }
    `;

    const response = await ai.models.generateContent({
      model,
      contents: {
        parts: [
          { inlineData: { mimeType: mimeType, data: videoData } },
          { text: prompt }
        ]
      },
      config: { responseMimeType: "application/json", temperature: 0.1 }
    });

    const result = JSON.parse(response.text.trim());
    const formattedTranscript = (result.script || []).map(line => `${line.speakerId}: ${line.text}`).join('\n');
    const speakers = (result.speakers || []).map(s => ({
      id: s.id,
      gender: s.gender?.toUpperCase() === 'FEMALE' ? 'FEMALE' : 'MALE'
    }));

    res.json({ transcript: formattedTranscript, speakers });
  } catch (error) {
    console.error("Server Analysis Error:", error);
    res.status(500).json({ error: error.message });
  }
});

// API Endpoint: Generate Multi-Speaker Audio
app.post('/api/generate-audio', async (req, res) => {
  try {
    const { analysis } = req.body;
    const apiKey = process.env.API_KEY;
    if (!apiKey) return res.status(500).json({ error: "Server API_KEY is missing." });

    const ai = new GoogleGenAI({ apiKey });
    const model = "gemini-2.5-flash-preview-tts"; 

    const speakerConfigs = analysis.speakers.map((s, idx) => ({
      speaker: s.id,
      voiceConfig: { 
        prebuiltVoiceConfig: { 
          voiceName: s.gender === 'FEMALE' ? 'Kore' : (idx % 2 === 0 ? 'Fenrir' : 'Puck')
        } 
      }
    }));

    const response = await ai.models.generateContent({
      model,
      contents: { parts: [{ text: analysis.transcript }] },
      config: {
        responseModalities: [Modality.AUDIO],
        speechConfig: {
          multiSpeakerVoiceConfig: {
            speakerVoiceConfigs: speakerConfigs
          }
        }
      }
    });

    const audioBase64 = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
    if (!audioBase64) throw new Error("Audio synthesis failed");

    res.json({ audioBase64 });
  } catch (error) {
    console.error("Server Audio Error:", error);
    res.status(500).json({ error: error.message });
  }
});

// For any other route, serve the frontend index.html (SPA support)
app.get('*', (req, res) => {
  res.sendFile(path.join(__dirname, 'dist', 'index.html'));
});

app.listen(port, () => {
  console.log(`Server running on port ${port}`);
});
